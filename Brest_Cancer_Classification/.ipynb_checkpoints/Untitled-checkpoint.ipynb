{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Important lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "# Importing the data set from the one provbided by sklearn\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_breast_cancer()\n",
    "\n",
    "X = ds['data']\n",
    "y = ds['target']\n",
    "\n",
    "y_label_in_string = ds['target_names']\n",
    "X_label_in_string = ds['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data (Most thing have been done since thid is a clean data i would just be spliting the data into trainging and testing data)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.23549918,  0.52039644, -0.27580173, -0.30881832, -0.72743243,\n",
       "       -0.74379329, -0.68306815, -0.62124714,  0.03560088, -0.79885176,\n",
       "       -0.49763462,  0.5554968 , -0.39050527, -0.40971233, -0.50100538,\n",
       "       -0.27527012, -0.44386995, -0.84312308, -0.25620847, -0.66924459,\n",
       "       -0.42744603,  0.5429047 , -0.42321933, -0.45572155, -0.79158353,\n",
       "       -0.54658376, -0.71545869, -0.8790558 , -0.41743136, -0.94855816])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling (I wa think there was no need for scaling the data but it turns out that without scaling the data, the algorithm would get to it max iteration even before the the learningprocess is done here by causing waste of computation)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traing the model (Since this is a bin classification i would prefer using the logistic regresson, by the way this is athe best in cases like this)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 50)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1\n",
      " 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1\n",
      " 0 0 1]\n",
      "[1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1\n",
      " 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1\n",
      " 0 0 1]\n",
      "[[39  0]\n",
      " [ 0 75]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction and socring the LogReg model\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(cm)\n",
    "\"\"\"\n",
    "    From what i am seeing it turning of that the model is 100 percent correct WONDERFUL,\n",
    "    NOTE: If prediction is 1 the Brest cancer staus is benign and if 0 status is malignant\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
